# What is Big O Notation?

Big O Notation is what's used in computer science to measure the speed and efficiency of an algorithm. Similar to cars, which use MPG to dictate a cars efficency, given a users input to the gas petal during the duration of the trip, as a form of measurement - big O notation measures the efficiency of a computer algorithm.

With Big O Notation, you express the runtime in terms of how quickly it grows relative to the size of the input. Essentially, it's a way to draw insights into how scalable an algo is.

It doesn't necessarily tell you how **fast** or **slow** an algo will run, but instead how it changes with the respect to its input size.

# What is space and time complexity?
